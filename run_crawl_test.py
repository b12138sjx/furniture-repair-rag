#!/usr/bin/env python3
"""
æµ‹è¯•çˆ¬è™«åŠŸèƒ½
"""
import os
import sys

def test_crawler():
    print("ğŸ•·ï¸ æµ‹è¯•çˆ¬è™«åŠŸèƒ½...")
    
    # åˆ‡æ¢åˆ°åç«¯ç›®å½•
    os.chdir("backend")
    
    # å¯¼å…¥çˆ¬è™«æœåŠ¡
    from crawler_service import crawler_service
    
    # 1. æ£€æŸ¥çˆ¬è™«çŠ¶æ€
    print("\nğŸ“Š æ£€æŸ¥çˆ¬è™«çŠ¶æ€...")
    status = crawler_service.get_crawler_status()
    print(f"æ•°æ®æ–‡ä»¶å­˜åœ¨: {status['data_file_exists']}")
    print(f"é“¾æ¥æ–‡ä»¶å­˜åœ¨: {status['urls_file_exists']}")
    print(f"æ•°æ®æ¡æ•°: {status['data_count']}")
    print(f"é“¾æ¥æ•°é‡: {status['urls_count']}")
    
    # 2. å¦‚æœæ•°æ®ä¸å­˜åœ¨ï¼Œè¿è¡Œçˆ¬è™«
    if not status['data_file_exists'] or status['data_count'] == 0:
        print("\nğŸš€ è¿è¡Œçˆ¬è™«è·å–æ•°æ®...")
        result = crawler_service.run_crawler()
        
        if result['success']:
            print("âœ… çˆ¬è™«è¿è¡ŒæˆåŠŸ!")
            print(result['message'])
        else:
            print("âŒ çˆ¬è™«è¿è¡Œå¤±è´¥:")
            print(result['message'])
            return False
    
    # 3. åŠ è½½æ•°æ®æµ‹è¯•
    print("\nğŸ“– æµ‹è¯•æ•°æ®åŠ è½½...")
    data = crawler_service.load_crawled_data()
    print(f"æˆåŠŸåŠ è½½ {len(data)} æ¡æ•°æ®")
    
    if data:
        print("ğŸ“‹ æ•°æ®æ ·ä¾‹:")
        sample = data[0]
        print(f"  æ ‡é¢˜: {sample.get('title', '')[:50]}...")
        print(f"  URL: {sample.get('url', '')}")
        print(f"  å†…å®¹é•¿åº¦: {len(sample.get('content', ''))} å­—ç¬¦")
    
    return True

if __name__ == "__main__":
    success = test_crawler()
    if success:
        print("\nğŸ‰ çˆ¬è™«æµ‹è¯•å®Œæˆï¼ç°åœ¨å¯ä»¥å¯åŠ¨åç«¯æœåŠ¡:")
        print("python simple_server.py")
    else:
        print("\nâŒ çˆ¬è™«æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥å’Œé…ç½®")
