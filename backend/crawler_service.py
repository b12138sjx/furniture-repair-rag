import os
import json
import subprocess
import sys
from typing import List, Dict

class CrawlerService:
    """çˆ¬è™«æœåŠ¡ç±»"""
    
    def __init__(self, data_dir="data/raw"):
        self.data_dir = data_dir
        self.crawler_script = os.path.join(data_dir, "web scrap.py")
        
    def run_crawler(self) -> Dict:
        """è¿è¡Œçˆ¬è™«è·å–æœ€æ–°æ•°æ®"""
        try:
            print("ğŸ•·ï¸ å¯åŠ¨çˆ¬è™«æœåŠ¡...")
            
            # åˆ‡æ¢åˆ°æ•°æ®ç›®å½•
            original_dir = os.getcwd()
            os.chdir(self.data_dir)
            
            # è¿è¡Œçˆ¬è™«è„šæœ¬
            result = subprocess.run([
                sys.executable, "web scrap.py"
            ], capture_output=True, text=True, timeout=300)
            
            # æ¢å¤ç›®å½•
            os.chdir(original_dir)
            
            if result.returncode == 0:
                print("âœ… çˆ¬è™«è¿è¡ŒæˆåŠŸ")
                return {
                    "success": True,
                    "message": "çˆ¬è™«è¿è¡ŒæˆåŠŸ",
                    "output": result.stdout,
                    "files_updated": self.get_updated_files()
                }
            else:
                print(f"âŒ çˆ¬è™«è¿è¡Œå¤±è´¥: {result.stderr}")
                return {
                    "success": False,
                    "message": "çˆ¬è™«è¿è¡Œå¤±è´¥",
                    "error": result.stderr
                }
                
        except subprocess.TimeoutExpired:
            return {
                "success": False,
                "message": "çˆ¬è™«è¿è¡Œè¶…æ—¶"
            }
        except Exception as e:
            return {
                "success": False,
                "message": f"çˆ¬è™«è¿è¡Œé”™è¯¯: {str(e)}"
            }
    
    def get_updated_files(self) -> List[str]:
        """è·å–æ›´æ–°çš„æ–‡ä»¶åˆ—è¡¨"""
        files = []
        for filename in ["phone.json", "phone urls.txt"]:
            filepath = os.path.join(self.data_dir, filename)
            if os.path.exists(filepath):
                files.append(filepath)
        return files
    
    def load_crawled_data(self) -> List[Dict]:
        """åŠ è½½çˆ¬å–çš„æ•°æ®"""
        json_file = os.path.join(self.data_dir, "phone.json")
        
        if not os.path.exists(json_file):
            print(f"âš ï¸ çˆ¬å–æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {json_file}")
            return []
        
        try:
            with open(json_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
                print(f"âœ… æˆåŠŸåŠ è½½ {len(data)} æ¡çˆ¬å–æ•°æ®")
                return data
        except Exception as e:
            print(f"âŒ åŠ è½½çˆ¬å–æ•°æ®å¤±è´¥: {e}")
            return []
    
    def get_crawler_status(self) -> Dict:
        """è·å–çˆ¬è™«çŠ¶æ€"""
        json_file = os.path.join(self.data_dir, "phone.json")
        urls_file = os.path.join(self.data_dir, "phone urls.txt")
        
        status = {
            "data_file_exists": os.path.exists(json_file),
            "urls_file_exists": os.path.exists(urls_file),
            "data_count": 0,
            "urls_count": 0,
            "last_updated": None
        }
        
        if status["data_file_exists"]:
            try:
                with open(json_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    status["data_count"] = len(data)
                status["last_updated"] = os.path.getmtime(json_file)
            except:
                pass
        
        if status["urls_file_exists"]:
            try:
                with open(urls_file, 'r', encoding='utf-8') as f:
                    urls = [line.strip() for line in f if line.strip()]
                    status["urls_count"] = len(urls)
            except:
                pass
        
        return status

# å…¨å±€çˆ¬è™«æœåŠ¡å®ä¾‹
crawler_service = CrawlerService()
