import os
import shutil
from typing import Dict, List
from .data_loader import DataLoader
from .furniture_crawler import FurnitureCrawler

class DataIntegration:
    """æ•´åˆç°æœ‰æ•°æ®å’Œæ–°çˆ¬è™«åŠŸèƒ½"""
    
    def __init__(self, base_dir: str = "data"):
        self.base_dir = base_dir
        self.raw_data_dir = os.path.join(base_dir, "raw")
        self.processed_data_dir = os.path.join(base_dir, "processed")
        self.ensure_directories()
    
    def ensure_directories(self):
        """ç¡®ä¿ç›®å½•å­˜åœ¨"""
        os.makedirs(self.raw_data_dir, exist_ok=True)
        os.makedirs(self.processed_data_dir, exist_ok=True)
    
    def migrate_our_data(self, our_data_path: str = "our_data"):
        """è¿ç§»our_dataç›®å½•ä¸‹çš„æ•°æ®"""
        if not os.path.exists(our_data_path):
            print(f"æºç›®å½•ä¸å­˜åœ¨: {our_data_path}")
            return
        
        # å¤åˆ¶æ–‡ä»¶åˆ°æ–°çš„æ•°æ®ç›®å½•
        for filename in os.listdir(our_data_path):
            src_path = os.path.join(our_data_path, filename)
            dst_path = os.path.join(self.raw_data_dir, filename)
            
            if os.path.isfile(src_path):
                shutil.copy2(src_path, dst_path)
                print(f"å·²è¿ç§»: {filename}")
    
    def process_existing_data(self) -> Dict:
        """å¤„ç†ç°æœ‰æ•°æ®"""
        phone_json_path = os.path.join(self.raw_data_dir, "phone.json")
        phone_urls_path = os.path.join(self.raw_data_dir, "phone urls.txt")
        
        # åˆå¹¶æ•°æ®æº
        merged_data = DataLoader.merge_data_sources(phone_json_path, phone_urls_path)
        
        # ä¿å­˜å¤„ç†åçš„æ•°æ®
        output_path = os.path.join(self.processed_data_dir, "integrated_repair_data.json")
        DataLoader.save_processed_data(merged_data, output_path)
        
        return merged_data
    
    def run_new_crawl(self, start_urls: List[str] = None) -> Dict:
        """è¿è¡Œæ–°çš„çˆ¬è™«ä»»åŠ¡"""
        if start_urls is None:
            start_urls = ["/Device/Furniture"]  # å¯ä»¥æ”¹ä¸ºå®¶å…·ç›¸å…³çš„èµ·å§‹URL
        
        crawler = FurnitureCrawler(start_urls)
        
        # è®¾ç½®è¾“å‡ºè·¯å¾„
        output_json = os.path.join(self.processed_data_dir, "new_crawl_results.json")
        output_urls = os.path.join(self.raw_data_dir, "new_urls.txt")
        
        # æ‰§è¡Œçˆ¬å–
        results = crawler.crawl(output_json, output_urls)
        
        return {
            'documents': DataLoader.convert_to_documents(results, "new_furniture_guide"),
            'urls': list(crawler.saved_links),
            'stats': {
                'total_documents': len(results),
                'total_urls': len(crawler.saved_links)
            }
        }
    
    def create_unified_dataset(self) -> Dict:
        """åˆ›å»ºç»Ÿä¸€çš„æ•°æ®é›†"""
        print("ğŸ”„ å¼€å§‹æ•´åˆæ•°æ®...")
        
        # 1. è¿ç§»ç°æœ‰æ•°æ®
        self.migrate_our_data()
        
        # 2. å¤„ç†ç°æœ‰æ•°æ®
        existing_data = self.process_existing_data()
        
        # 3. åˆ›å»ºç»Ÿä¸€æ•°æ®é›†
        unified_data = {
            'metadata': {
                'source': 'integrated_dataset',
                'version': '1.0',
                'description': 'æ•´åˆçš„å®¶å…·/è®¾å¤‡ç»´ä¿®çŸ¥è¯†åº“'
            },
            'documents': existing_data['documents'],
            'urls': existing_data['urls'],
            'stats': existing_data['stats']
        }
        
        # 4. ä¿å­˜ç»Ÿä¸€æ•°æ®é›†
        unified_path = os.path.join(self.processed_data_dir, "unified_repair_dataset.json")
        DataLoader.save_processed_data(unified_data, unified_path)
        
        print(f"âœ… æ•°æ®æ•´åˆå®Œæˆ!")
        print(f"ğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
        print(f"   - æ–‡æ¡£æ•°é‡: {unified_data['stats']['total_documents']}")
        print(f"   - URLæ•°é‡: {unified_data['stats']['total_urls']}")
        print(f"   - æ•°æ®æ–‡ä»¶: {unified_path}")
        
        return unified_data

def main():
    """ä¸»å‡½æ•° - æ‰§è¡Œæ•°æ®æ•´åˆ"""
    integration = DataIntegration()
    result = integration.create_unified_dataset()
    return result

if __name__ == "__main__":
    main()
